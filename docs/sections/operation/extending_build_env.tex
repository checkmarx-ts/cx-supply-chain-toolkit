\chapter{Integrating \scaresolver into Build Environments}\label{chap:ext_build_env}

The Checkmarx \scaresolver is the scan command line tool that invokes 
dependency scans locally.  It can be invoked directly or as part of another
tool such as \cxflow, the \cxonecli, or other Checkmarx plugins.  

\noindent\\
\textit{
    Please note: While some of these techniques can be applied for 
    integration with \cxone supply chain scans, this document is
    currently focused on solutions using \cxsca.  Future versions will cover
    more \cxone supply chain scan integration topics.
}

\section{Deploying on a Build Agent}

When builds are executed on a specific build agent (a.k.a. "The Build Box"),
the invocation of \scaresolver will typically be scripted to execute
withing a pipeline stage.  In this scenario, the \scaresolver should be
installed on all build agents that will run pipelines that have scripted
a supply chain scan invocation.

Note that in this scenario, updates to \scaresolver will need to be
periodically installed.  There are likely several tools on the build agent
that need periodic update; \scaresolver will simply be one additional
tool that requires occasional update.

\section{Modifying a Containerized Build Environment}

A variation of the build agent deployment is found when containerized
build environments are defined as the execution environment for
pipeline stages.  The supply chain scan invocation is scripted similar
to how it would be invoked when using a build agent.  The main difference
is that the pipeline stage is configured to execute inside a specified
container image.  The container image contains all the tools required
to successfully build the software, which means that an accurate
dependency tree can also be generated if the \scaresolver is invoked
in that build environment.

In this integration scenario, the container definition can be modified to install \scaresolver
as part of the container build.  The pipeline scripting running in the container
will invoke \scaresolver as it would invoke any other tool in the scripted
build steps.  

\section{Containerized Build Environment Extension}\label{sec:extending_environment}

Often it is difficult to modify the build agent installation or the build
container definition to add \scaresolver.  It may also present some
difficulties in deployment for some pipeline architectures.  Another option
is to create new container instances that derive from already defined build
environments.  This has several advantages:

\begin{itemize}
    \item No instability can be introduced into known-stable build environments.
    \item The \scaresolver updates can be applied without modifying any 
    containerized build environments.
    \item Deployment of updates is a simple rebuild of the extended containers.
    \item The \cxtoolkit provides a way to generate the extended build 
    environment image for build images running on popular Linux distributions.
    \item The image in the \cxtoolkit also provides some isolation of 
    dependency resolution activities to avoid some attacks associated with 
    malware embedded in typo-squatted packages.
\end{itemize}

\noindent\\The "build-environment" components can be obtained from the \cxtoolkitpath{releases/latest}{Releases}.


\subsection{Creating Extended Images}

The build-environment components contains a \texttt{Dockerfile} is multi-stage where stage names
specify the correct variation of Linux\footnote{There is currently no support for Windows base images.}
in the base image.  The stage names are intended to align 
with popular base images used to create build environments.  The \texttt{Dockerfile} stages
execute the commands specific to the Linux OS distribution of the base image to properly configure
\scaresolver.

Any image that can be pulled from the public Docker Hub or a private docker registry connected via 
\texttt{docker login} can be defined as the base image.  If the wrong or incompatible stage is specified, 
the container build will fail. To see the base image Linux distribution, one possible method would be
to view the \texttt{/etc/os-release} file found in the base image.  This can be done by executing the following
command:

\noindent\\\\\texttt{docker run --rm -it --entrypoint=cat <base image tag> /etc/os-release}

\subsection{How to Build an Extended Image}

Building the extended image is done via a \texttt{docker build} command.
\footnote{These instructions can likely be adapted to other container build tools.  Docker is used here since it is
the most commonly used container toolkit at the time this manual was written.}
Docker \href{https://docs.docker.com/build/guide/build-args/}{build arguments} control how the extended image build
is performed.  The most important argument is the \hyperref[sec:BASE]{\textbf{BASE}} build argument.  Other build
arguments are available; details of the available arguments can be found in Appendix \ref{chap:build_args}.

\noindent\\Example build commands:

\begin{code}{Extending Gradle 8.0 Alpine with JDK19}{[with Entrypoint]}{}
docker build -t <your tag> --build-arg BASE=gradle:8.0-jdk19-alpine \
    --target=resolver-alpine .
\end{code}

\begin{code}{Extending Gradle 8.0 Alpine with JDK19}{[without Entrypoint]}{}
docker build -t <your tag> --build-arg BASE=gradle:8.0-jdk19-alpine \
    --target=resolver-alpine-bare .
\end{code}

\begin{code}{Extending Node 19 Alpine}{[with Entrypoint]}{}
docker build -t <your tag> --build-arg BASE=node:19-alpine \
    --target=resolver-alpine .
\end{code}

\begin{code}{Extending Node 19 Alpine}{[without Entrypoint]}{}
docker build -t <your tag> --build-arg BASE=node:19-alpine \
    --target=resolver-alpine-bare .
\end{code}
    
\begin{code}{Extending Node 19 Buster (Debian)}{[with Entrypoint]}{}
    docker build -t <your tag> --build-arg BASE=node:19-buster \
        --target=resolver-debian .
\end{code}

\begin{code}{Extending Node 19 Buster (Debian)}{[without Entrypoint]}{}
docker build -t <your tag> --build-arg BASE=node:19-buster \
    --target=resolver-debian-bare .
\end{code}

\subsection{Extended Image Build Customizations}

There are sub-directories in the build-environment toolkit that are used as part of Building
the extended image.  Items can be add or modified in these directories as appropriate.

\subsubsection{CA Certificates}

The \texttt{cacerts} directory contains Amazon AWS Root CA certs that are used as the CA 
certificate for Checkmarx services.  You can add your own PEM encoded CA certificates in this
directory and it will be included as a trusted CA by the image.

If desired, you can remove the AWS CA files as long as there is at least one PEM
encoded certificate left in the directory during image build.

\subsubsection{\scaresolver Configuration YAML}

The \texttt{default-config} folder contains the \texttt{Configuration.yml} file with a default
configuration for \scaresolver.  It is possible to modify the default configuration so that
common parameter values are not needed to be provided for every invocation of \scaresolver.

\subsection{Dockerfile Targets with Entrypoints}\label{ssec:entrypoint_targets}

If you want to invoke \scaresolver in the extended image in the same way it is invoked from the command
line if it were locally installed, use the entrypoint targets.  If you intend to use the
extended images with the \cxtoolkit 
tools for \hyperref[chap:build_env_affinity]{webhook} scan workflows, extended
images with entrypoints are required.  The current targets that build the extended
image with an entry point are:

\begin{itemize}
    \item \texttt{resolver-alpine}
    \item \texttt{resolver-debian}
    \item \texttt{resolver-redhat}
    \item \texttt{resolver-amazon}
\end{itemize}


\subsection{Bare Dockerfile Targets}\label{ssec:bare_targets}

Containers built with these targets have no entrypoint and run as root.  
CI/CD pipelines will sometimes need the ability to execute environment
configuraton commands as root before the stage is executed.  Some CI/CD pipelines
will allow the entrypoint to be overridden and will successfully execute the stage
in the container image.  Some CI/CD pipelines, like Azure Devops, are not compatible
with images that define an entrypoint.  

If your CI/CD pipeline needs a container image without an entrypoint, these targets will
produce extended images without an entrypoint:

\begin{itemize}
    \item \texttt{resolver-alpine-bare}
    \item \texttt{resolver-debian-bare}
    \item \texttt{resolver-redhat-bare}
    \item \texttt{resolver-amazon-bare}
\end{itemize}


\subsection{Sandboxed Entrypoint Containers}

Building extended images with entrypoint targets will "sandbox" \scaresolver execution 
to the extent possible. This is to allow \scaresolver to execute a dependency resolution
while minimizing the risk of detonating malware payloads found in untrusted build scripts or 
package installation scripts. This is not universally a problem with all dependencies, but 
there is always the possibility for malware delivery via dependencies.  If there was not, 
no one would be performing supply-chain security scans.

In terms of sandboxing, the extended images with entrypoints perform the following sandboxing
activities:

\begin{itemize}
    \item The local user executing the scan has limited privileges.
    \item Code for scanning is provided in a read-only volume map.
    This blocks dependencies that execute code-modifying malware from mutating scanned code.
    \item Output volume maps are write-only, preventing the vulnerability reports and logs
    from being exfiltrated as part of exploitable vulnerability intelligence gathering activities.
\end{itemize}

Nothing is foolproof; don't expect that using this container alone hardens your build
environment.  A threat modeling exercise should be undertaken to understand
if there are other infrastructure changes needed to properly control what is executed in your
build environments.

\subsection{Invoking the Sandbox Container CLI Style}

Extended images with entrypoints can be invoked to use \scaresolver the same way
it would be invoked from the command line with a local install.  Any of the 
\scaresolver
\href{https://checkmarx.com/resource/documents/en/34965-132888-checkmarx-sca-resolver-configuration-arguments.html}{command line arguments}
are passed to the container.  A typical execution is shown below:


\begin{code}{Extended Container Typical CLI Invocation}{}{}
docker run --rm -it \
    -v /my-log-path:/sandbox/scalogs \
    -v .:/sandbox/input \
    -v ./sca-results:/sandbox/output \
    my-scaresolver-tag <SCAResolver args...>
\end{code}

To properly interface with the container, some directories are intended to be mapped 
to a volume at runtime.  Table \ref{table:volume_maps} shows the available volume map
paths.


\begin{table}[h]
    \caption{Container Volume Maping Paths}\label{table:volume_maps}      
    \begin{tabularx}{\textwidth}{lcl}
        \toprule
        \textbf{Container Directory} & \textbf{Required} & \textbf{Description}\\
        \midrule
        \texttt{/sandbox/scalogs} & N & \makecell[l]{Used to write \scaresolver logs.}\\
        \midrule
        \texttt{/sandbox/input} & Y & \makecell[l]{This is where the input should be mapped\\
        for \scaresolver inputs.}\\
        \midrule
        \texttt{/sandbox/output} & Y & \makecell[l]{This is the directory where \scaresolver\\
        results files will be written.}\\
        \midrule
        \texttt{/sandbox/report} & Y & \makecell[l]{This is the directory where \scaresolver\\
        report will be written.}\\
        \bottomrule
    \end{tabularx}
\end{table}

Note that options passed to \scaresolver that indicate where to place output should be provided 
with paths prefixed with \texttt{/sandbox}.  This is the location in the container where you 
have mapped a volume in the \texttt{docker run} command.

